---
title: " Hierarchical spatio-temporal modeling of resting state fMRI: an Application to Multivatiate Time Series Data"
author: "Caponera, Denti, Gelfand, Rigon, Sottosanti"
date: "Last update: April 2018"
output: 
 html_document:
    keep_md: true
---

```{r, message=F, echo=F}
options(knitr.kable.NA = '')
library(reshape2); library(lubridate)
library(ggplot2);  library(tidyverse)
library(ranger);   library(MTS)
library(klin);     library(dplyr)
library(coda);     library(ggmcmc)
library(stringr);  library(doParallel)
library(forecast); library(vars)
library(doMC);     library(ggcorrplot)
library(gridExtra)
cl <- makeCluster(getOption("cl.cores", 3))
```

## Introduction
In this repository we apply the statistical methodology developed in the paper ``Hierarchical spatio-temporal modeling of resting state fMRI'' to a financial dataset, provided in the R package \texttt{MTS}. 
Motivated by \emph{rs-FMRI} data, our work provides a flexible and parsimonious setting for areally-referenced time series. Since in various applications a neighborhood matrix is not available and the idea of which distance to use is not always completely clear, our model does not rely on any distance concept. This assumption makes our model robust with respect to the definition of distance, and hence allows us to apply our methodology to different types of data. One simple example of the  structures that our model is able to handle is given by \emph{multivariate time series}.
More precisely, we use our model to describe the relationships among the time series, providing as output an estimate of the covariance matrix which could be useful for the sake of interpretability and description of the phenomenon under study.

## Data Analysis
To testify the adaptability of model, we apply our setting to describe the covaraince structure among ten time series, referring to simple monthly returns of ten U.S. stocks. As already stated,  The dataset `tenstocks` is available in the package `MTS`.
First of all, since our model was developed for zero-mean time series, we center the data. Let us have a glimpse of our data with the following plot.

```{r, fig.width= 10, message=F }
# This load the dataset
data("mts-examples")
dd                  <- as.character(tenstocks[,1])
dd                  <- as.Date(dd,"%Y %m %d")
DAT                 <- as.data.frame(apply(tenstocks[,-1],2,function(x) scale(x, center = T, scale = F)))
DAT$date            <- dd
data.plot           <- melt(DAT,id.vars = "date")
colnames(data.plot) <- c("Time","Stock","Value")
data.plot           <- as.tibble(data.plot)
ggplot(data=data.plot, aes(x=Time,y=Value,group=Stock)) + geom_line(alpha=0.60,aes(col=Stock)) + theme_bw() + xlab("Time") + ylab("Value") +ggtitle("Centered monthly simple returns of ten U.S. stocks")
```

One can naively describe the correlation structure computing the Pearson Correlation Coefficient. An example is reported in the following raster plot. 
Spurious correlation, arised by time dependency, could be present in this first result. However, this matrix could be a useful benchmark. 
To support our last claim, we report also the ACF plots (in a time series form, to improve interpretability). 

```{r, fig.width= 10, message=F, warning=F}
DAT <- DAT[,-11]

# Pearson correlation
Pear_10 <- cor((DAT))
ggcorrplot(Pear_10,ggtheme=ggplot2::theme_dark,colors=c("red","white","blue"),legend.title="Correlation") +ggtitle("Pearson correlation index among monthly simple returns of ten U.S. stocks")

# Autocorrelation
ACF_10           <- matrix(0,21,10)
for(l in 1:10) {ACF_10[,l] <- acf(DAT[,l],plot=FALSE,lag.max=20)$acf[,,1]}
ACF_10           <- as.data.frame(ACF_10)
colnames(ACF_10) <- colnames((DAT))
ACF              <- rbind(melt(ACF_10))
ACF$ind          <- rep(0:20,10)

ggplot(data=ACF,aes(x=ind,y=value,group=variable)) + geom_line(aes(col=variable), alpha=.8,size=0.5) + geom_point(aes(col=variable),size=0.4)+ geom_hline(yintercept=0) + ylab("Autocorrelation") + xlab("Lag") + theme_bw()  + scale_x_continuous(breaks = round(seq(0, 19, by = 1))) + geom_hline(yintercept =qnorm(c(0.025, 0.975))/sqrt(nrow(DAT)),col=2)+ggtitle("Autocorrelation Plot, Maximum lag set to 20")
```

From the correlation matrix, two ``clusters'' of highly correlated time series appear. Moreover, even if it is not so remarkable, some kind of autocorrelation seems to be present among the ten stocks. We then prepare the data for being processed by our model and we import our functions. 

```{r}
source("/home/fra/Downloads/StartUpResearch-master/TenStockApplication/functions.R")
DAT   <- t(DAT)
n_t   <- ncol(DAT)             # Number of time observations
n_l   <- nrow(DAT)             # Number of generated processes
colnames(DAT) <- 1:n_t;        # Set the names of the colums
time  <- seq(0,ncol(DAT),length=ncol(DAT))
```

In order to perform in-sample prediction we create two mutually exclusive grids of points. The `DAT' dataset is then splitted into two parts: training and test.

```{r}
set.seed(123)
time_grid <- sort(sample(n_t,round(0.75*n_t))) # The 75% of the time columns are used.
new_grid  <- setdiff(1:n_t,time_grid)          # Grid for prediction
DAT_train <- DAT[,time_grid]
DAT_test  <- DAT[,new_grid]
```

After having splitted the data into train and test dataset, we firstly run 15000 iterations and we discard 5000 of them as burn-in period (thinning step of 5 observations) for $K\in\{2,3,4\}$, as suggested by the previous exploratory plots.

```{r, eval=F}
r <- foreach(k=2:3) %dopar% {
  prior             <- list(a_sigma = 0.001, b_sigma = 0.001, gamma2 = 100, K = k, psi= 0.03)
  Sigma_Metropolis  <- cov(bootPPCA(t(DAT_train),prior$K,R=1000))
  tuning            <- list(cholSigmaMetropolis = chol(Sigma_Metropolis))
  Metropolis_MCMC(DAT_train, time_grid, prior, 
                                       Iter=10000, burn_in=5000, start= NULL, 
                                       thinning=5, tuning, verbose = TRUE)
}
#save(r,file="Parallel_results2_3.Rdata")

prior             <- list(a_sigma = 0.001, b_sigma = 0.001, gamma2 = 100, K = 2, psi= 0.03)
Sigma_Metropolis  <- cov(bootPPCA(t(DAT_train),prior$K,R=1000))
tuning            <- list(cholSigmaMetropolis = chol(Sigma_Metropolis))
r2 <- Metropolis_MCMC(DAT_train, time_grid, prior, 
                                       Iter=1000000, burn_in=250000, start= NULL, 
                                       thinning=5, tuning, verbose = TRUE)
#save(r2,file="Parallel_results2.Rdata")
```

```{r, echo=F}
load(file="/home/fra/Documents/SUR_END NOV 17/File_R/applicazione a 10 stock/Parallel_results2.Rdata")
load(file="/home/fra/Documents/SUR_END NOV 17/File_R/applicazione a 10 stock/Parallel_results2_6.Rdata")
```

```{r}
# -----------------------------------
# Model summary
# -----------------------------------
model_summary                  <- data.frame(K=c(2:4),rbind(t(unlist(sapply(r,function(x) IC(x)))))[1:3,])
colnames(model_summary)[2:4]   <- c("DIC",  "p","p_DIC")
model_summary$Acceptance_ratio <- c(sapply(r, function(x) x$acceptance_ratio)[1:3])
model_summary$MAP              <- c(sapply(r, function(x) max(x$logpost))[1:3])
model_summary$RMSE_train       <- c(
    sapply(r,function(x) sqrt(mean((DAT_train - predict(x, DAT_train, 1:n_t)[,time_grid])^2))))[1:3]

model_summary$RMSE_test        <- c(  sapply(r,function(x) sqrt(mean((DAT_test - predict(x, DAT_train, 1:n_t)[,new_grid])^2))))[1:3]
knitr::kable(model_summary,digits=4,format = "markdown")
```

Computational issues seem to arise as $K$ increases.
The best choice of $K$ according to the DIC criterion is $K=2$. We run again a longer MCMC chain fixing $K=2$. In particular, the number of simulations is set to 1000000, the thinning is set to 5 and the burn-in period is of 250000 observations. As an example, we report the Monte Carlo markov Chains for 3 parameters: $a_{11}, a_{a21}, a_{22}$ and $\sigma$.


```{r, fig.width=10, fig.height=10}
a           <- as.mcmc(   cbind(as.matrix(r2$A[,1:3,1]),r2$sigma2  )  )
colnames(a) <- c(rep(paste0("a[",c(11,21,31),"]")),"sigma")
aa          <- ggs(a)
a1          <- ggs_histogram(aa)+theme_bw()
a2          <- ggs_running(aa)+theme_bw() + theme(legend.position="none")
grid.arrange(a1, a2,  ncol=3, nrow=1)
```

The prediction on the test dataset is performed. We then have a look at the resulting plots for a qualitative assessment. The model seems to capture the mean of the process.

```{r, fig.width=10, fig.height=10}
data.plot_DAT                   <- melt(DAT); colnames(data.plot_DAT) <- c("Stock","Time","Value")
data.plot_DAT$In_sample         <- factor(rep(1:n_t %in% time_grid,n_l)); 
levels(data.plot_DAT$In_sample) <- c("No","Yes")
data.plot_DAT$Pred_test         <- c(predict(r2, DAT_train, 1:n_t))

colnames(data.plot_DAT)[5]      <- paste("K=",2)
data.plot_DAT2                  <- melt(data.plot_DAT,id.vars = c("Stock","Time","Value","In_sample"))

ggplot(data=data.plot_DAT2 , aes(x=Time,y=Value)) + geom_point(alpha=0.25) + facet_wrap(   ~  Stock,ncol=2 ) + geom_line(aes(y=value),col=4, size=1.2) + ylab("Price")+ ggtitle("Ten Stocks")+ theme_bw()
```

Let us have a look to the raster plot which describes the estimated covariance matrix. Notice that this estimation is built averaging each component of the matrix along the simulated chain.

```{r}
post_mean_A     <- apply((r2$A),c(2,3),mean)
post_mean_Sigma <- post_mean_A%*%t(post_mean_A)
CCC <- melt(post_mean_Sigma) %>% mutate(Value=value)

s2  <- ggplot(CCC)+geom_raster(aes(x=Var1, y=Var2, fill=Value))+ggtitle("Elementwise Posterior Mean of the Covariance Matrix")+theme_bw()+xlab("Stock")+ylab("Stock")+ scale_fill_gradient2(low=I("red"), high=I("yellow"),mid=I("darkblue"),midpoint = 0)
s2
```

We want compare the Out-of-sample performance of our model (MOD3) with the prediction ability of VAR model. To do so, we create new training and testing datasets, splitting the temporal line at $t=80$. The models are trained on the first eighty observations and then they are use to forecast the future 52 prices.

```{r,echo=F}
set.seed(123)
time_grid      <- 1:80   # VAR forecasts only in ahead. --> let us forecast!
new_grid       <- 81:132
DAT_train_pred <- DAT[,time_grid]
DAT_test_pred  <- DAT[,new_grid]
```

We run a MCMC simulation on the new training set. The values are left identical to the ones of the previous example.

```{r, eval=F}
prior             <- list(a_sigma = 0.001, b_sigma = 0.001, gamma2 = 100, K = 2, psi= 0.03)
Sigma_Metropolis  <- cov(bootPPCA(t(DAT_train_pred),prior$K,R=1000))
tuning            <- list(cholSigmaMetropolis = chol(Sigma_Metropolis))
r3 <- Metropolis_MCMC(DAT_train_pred, time_grid, prior, 
                                       Iter=1000000, burn_in=250000, start= NULL, 
                                       thinning=5, tuning, verbose = TRUE)
save(r3,file="Parallel_results2_prediction_1_80.R")
```

```{r, echo=F}
load(file="/home/fra/Documents/SUR_END NOV 17/File_R/applicazione a 10 stock/Parallel_results2_prediction_1_80.R")
```

The next plot shows the predicitons for the mean of the various processes. It seems to be a little more stable than the one predicted by the VAR. Moreover, recall that the time series have been standardized. We would expect that the predictions that one performs tend to converge to the mean of the process, as the time index shifts far away from the available data and less information is available. 
This desirable property can be appreciated in our model, as we can see in the plot below. The VAR model, on the other hand, for some of the time series seems to be more affected by the noise (e.g. TXN, MS).

```{r, fig.width=10, fig.height=10}
pred_mod3 <- t(predict.model3(r3, DAT_train_pred, 1:132)[,new_grid])
varmod    <- VAR(t(DAT_train_pred),p=2)
pred_vars <- predict(varmod,n.ahead = 132-80)

pred_vars_simple <- sapply(pred_vars[[1]], function(x) x[,1]   )
p1               <- melt(t(DAT_test_pred))
p2               <- melt((pred_vars_simple))
p3               <- melt((pred_mod3))

p4 <- melt(cbind(p1,
                 VAR=p2[,3],MOD3=p3[,3]), id.vars = c("Var1","Var2"))
p4 <- p4 %>% arrange(Var2) %>% mutate(ind=as.factor(c(rep(" ",1560/2),rep("  ",1560/2))))
ggplot(data=p4 %>% filter( variable!="value"), aes(x=Var1))+geom_line(aes(y=value,col=(variable)) )+facet_wrap(~Var2)+xlab("Time")+ylab("Price, VARs, Model")+theme_bw()+geom_abline(intercept = 0,slope=0,lty=2)
```

Finally, we can state that our model does a slightly better job in comparison with a model well suited for time series. In fact, the MSE of the VAR model is given by `r mean((t(DAT_test_pred)-pred_vars_simple)^2)` while our model scores an MSE of `r mean((t(DAT_test_pred)-pred_mod3)^2)`. 



